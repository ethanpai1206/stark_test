#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨æ­·å²åƒ¹æ ¼èˆ‡è²¡å‹™æ•¸æ“šåˆä½µè…³æœ¬
æ”¯æ´é¸æ“‡æ€§åˆä½µå¤šå€‹è²¡å‹™æ•¸æ“šè¡¨åˆ°historicalPriceFull.csvï¼ˆæ¯æ—¥æ•¸æ“šï¼‰
"""

import pandas as pd
from datetime import datetime, timedelta
import numpy as np

def get_quarter_date_range(year, quarter):
    """
    æ ¹æ“šå¹´ä»½å’Œå­£åº¦è¨ˆç®—è©²å­£åº¦çš„æ—¥æœŸç¯„åœ
    Q1: 1æœˆ1æ—¥è‡³3æœˆ31æ—¥
    Q2: 4æœˆ1æ—¥è‡³6æœˆ30æ—¥
    Q3: 7æœˆ1æ—¥è‡³9æœˆ30æ—¥
    Q4: 10æœˆ1æ—¥è‡³12æœˆ31æ—¥
    """
    if quarter == 'Q1':
        start_date = datetime(year, 1, 1)
        end_date = datetime(year, 3, 31)
    elif quarter == 'Q2':
        start_date = datetime(year, 4, 1)
        end_date = datetime(year, 6, 30)
    elif quarter == 'Q3':
        start_date = datetime(year, 7, 1)
        end_date = datetime(year, 9, 30)
    elif quarter == 'Q4':
        start_date = datetime(year, 10, 1)
        end_date = datetime(year, 12, 31)
    else:
        raise ValueError(f"Invalid quarter: {quarter}")
    
    return start_date, end_date

def merge_daily_data_to_historical(historical_df, daily_df, daily_name):
    """
    å°‡æ—¥è³‡æ–™åˆä½µåˆ°æ­·å²æ•¸æ“šä¸­ï¼ˆåŸºæ–¼æ—¥æœŸç›´æ¥åŒ¹é…ï¼‰
    
    Args:
        historical_df: æ­·å²åƒ¹æ ¼æ•¸æ“šDataFrame
        daily_df: æ—¥æŠ€è¡“æŒ‡æ¨™æ•¸æ“šDataFrame
        daily_name: æ—¥è³‡æ–™çš„åç¨±ï¼ˆç”¨æ–¼é¡¯ç¤ºï¼‰
    
    Returns:
        åˆä½µå¾Œçš„DataFrame
    """
    print(f"æ­£åœ¨åˆä½µ {daily_name} æ•¸æ“š...")
    
    # è¨­å®šæ—¥æœŸç‚ºç´¢å¼•ä»¥ä¾¿é€²è¡Œåˆä½µ
    historical_df = historical_df.set_index(['date', 'symbol'])
    daily_df = daily_df.set_index(['date', 'symbol'])
    
    # ç²å–æ—¥è³‡æ–™çš„æ‰€æœ‰åˆ—ï¼ˆé™¤äº†dateå’Œsymbolï¼‰
    daily_cols = [col for col in daily_df.columns]
    
    print(f"  å°‡åˆä½µ {len(daily_cols)} å€‹ {daily_name} æ¬„ä½")
    
    # ä½¿ç”¨left joinåˆä½µæ•¸æ“š
    result_df = historical_df.join(daily_df, how='left')
    
    # é‡è¨­ç´¢å¼•
    result_df = result_df.reset_index()
    
    # è¨ˆç®—æ•¸æ“šè¦†è“‹ç‡
    non_null_count = result_df[daily_cols].notna().any(axis=1).sum()
    total_count = len(result_df)
    coverage = (non_null_count / total_count) * 100
    
    print(f"  {daily_name} æ•¸æ“šè¦†è“‹ç‡: {coverage:.2f}% ({non_null_count}/{total_count})")
    
    return result_df

def merge_quarterly_data_to_historical(historical_df, quarterly_df, quarterly_name):
    """
    å°‡å­£åº¦æ•¸æ“šåˆä½µåˆ°æ­·å²æ•¸æ“šä¸­
    
    Args:
        historical_df: æ­·å²åƒ¹æ ¼æ•¸æ“šDataFrame
        quarterly_df: å­£åº¦è²¡å‹™æ•¸æ“šDataFrame
        quarterly_name: å­£åº¦æ•¸æ“šçš„åç¨±ï¼ˆç”¨æ–¼é¡¯ç¤ºï¼‰
    
    Returns:
        åˆä½µå¾Œçš„DataFrame
    """
    print(f"æ­£åœ¨åˆä½µ {quarterly_name} æ•¸æ“š...")
    
    # ç²å–å­£åº¦æ•¸æ“šçš„æ‰€æœ‰åˆ—ï¼ˆé™¤äº†dateå’Œsymbolï¼‰
    quarterly_cols = [col for col in quarterly_df.columns if col not in ['date', 'symbol']]
    
    # æ‰¹é‡æ·»åŠ æ–°åˆ—ï¼Œé¿å…é€ä¸€æ·»åŠ å°è‡´çš„æ€§èƒ½å•é¡Œ
    new_cols = [col for col in quarterly_cols if col not in historical_df.columns]
    if new_cols:
        # å‰µå»ºåŒ…å«æ–°åˆ—çš„DataFrameä¸¦ä¸€æ¬¡æ€§åˆä½µ
        new_cols_df = pd.DataFrame(index=historical_df.index, columns=new_cols)
        new_cols_df[:] = np.nan
        historical_df = pd.concat([historical_df, new_cols_df], axis=1)
    
    # æŒ‰symbolåˆ†çµ„è™•ç†
    for symbol in historical_df['symbol'].unique():
        if symbol not in quarterly_df['symbol'].values:
            continue
            
        print(f"  è™•ç†è‚¡ç¥¨ {symbol} çš„ {quarterly_name} æ•¸æ“š...")
        
        # ç²å–è©²è‚¡ç¥¨çš„æ­·å²æ•¸æ“šå’Œå­£åº¦æ•¸æ“š
        hist_symbol_idx = historical_df['symbol'] == symbol
        quarterly_symbol = quarterly_df[quarterly_df['symbol'] == symbol].copy()
        
        # ç‚ºæ¯ä¸€è¡Œæ­·å²æ•¸æ“šæ‰¾åˆ°å°æ‡‰çš„å­£åº¦æ•¸æ“š
        for idx in historical_df[hist_symbol_idx].index:
            hist_date = historical_df.loc[idx, 'date']
            
            # æ‰¾åˆ°åŒ…å«é€™å€‹æ—¥æœŸçš„å­£åº¦æ•¸æ“š
            for _, quarterly_row in quarterly_symbol.iterrows():
                year = quarterly_row['calendarYear']
                quarter = quarterly_row['period']
                
                # è¨ˆç®—è©²å­£åº¦çš„æ—¥æœŸç¯„åœ
                try:
                    quarter_start, quarter_end = get_quarter_date_range(year, quarter)
                    
                    # æª¢æŸ¥æ­·å²æ—¥æœŸæ˜¯å¦åœ¨è©²å­£åº¦ç¯„åœå…§
                    if quarter_start <= hist_date <= quarter_end:
                        # å°‡å­£åº¦æ•¸æ“šè¤‡è£½åˆ°çµæœDataFrame
                        for col in quarterly_cols:
                            historical_df.loc[idx, col] = quarterly_row[col]
                        break
                        
                except ValueError as e:
                    print(f"    è­¦å‘Š: {e} - è·³éè©²è¨˜éŒ„")
                    continue
    
    return historical_df

def merge_selected_data(selected_tables, daily_tables=None, historical_file='data/historicalPriceFull.csv'):
    """
    åˆä½µç”¨æˆ¶é¸æ“‡çš„æ•¸æ“šè¡¨
    
    Args:
        selected_tables: é¸æ“‡çš„å­£åº¦è¡¨æ ¼åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ ç‚º (æ–‡ä»¶è·¯å¾‘, è¡¨æ ¼åç¨±)
        daily_tables: é¸æ“‡çš„æ—¥è³‡æ–™è¡¨æ ¼åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ ç‚º (æ–‡ä»¶è·¯å¾‘, è¡¨æ ¼åç¨±)
        historical_file: æ­·å²åƒ¹æ ¼æ•¸æ“šæ–‡ä»¶è·¯å¾‘
    
    Returns:
        åˆä½µå¾Œçš„DataFrame
    """
    
    # è®€å–æ­·å²åƒ¹æ ¼æ•¸æ“š
    print("æ­£åœ¨è®€å–æ­·å²åƒ¹æ ¼æ•¸æ“š...")
    result_df = pd.read_csv(historical_file)
    result_df['date'] = pd.to_datetime(result_df['date'])
    
    print(f"æ­·å²æ•¸æ“šç¶­åº¦: {result_df.shape}")
    
    # é¦–å…ˆåˆä½µå­£åº¦è¡¨æ ¼
    for file_path, table_name in selected_tables:
        print(f"\n=== é–‹å§‹åˆä½µ {table_name} (å­£åº¦æ•¸æ“š) ===")
        
        try:
            # è®€å–å­£åº¦æ•¸æ“š
            quarterly_df = pd.read_csv(file_path)
            quarterly_df['date'] = pd.to_datetime(quarterly_df['date'])
            
            print(f"{table_name} æ•¸æ“šç¶­åº¦: {quarterly_df.shape}")
            
            # åˆä½µæ•¸æ“š
            result_df = merge_quarterly_data_to_historical(result_df, quarterly_df, table_name)
            
            print(f"{table_name} åˆä½µå®Œæˆ")
            
        except FileNotFoundError:
            print(f"è­¦å‘Š: æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}ï¼Œè·³é {table_name}")
        except Exception as e:
            print(f"åˆä½µ {table_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    # ç„¶å¾Œåˆä½µæ—¥è³‡æ–™è¡¨æ ¼
    if daily_tables:
        for file_path, table_name in daily_tables:
            print(f"\n=== é–‹å§‹åˆä½µ {table_name} (æ—¥è³‡æ–™) ===")
            
            try:
                # è®€å–æ—¥è³‡æ–™
                daily_df = pd.read_csv(file_path)
                daily_df['date'] = pd.to_datetime(daily_df['date'])
                
                print(f"{table_name} æ•¸æ“šç¶­åº¦: {daily_df.shape}")
                
                # åˆä½µæ—¥è³‡æ–™
                result_df = merge_daily_data_to_historical(result_df, daily_df, table_name)
                
                print(f"{table_name} åˆä½µå®Œæˆ")
                
            except FileNotFoundError:
                print(f"è­¦å‘Š: æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}ï¼Œè·³é {table_name}")
            except Exception as e:
                print(f"åˆä½µ {table_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    return result_df

def main():
    """
    ä¸»å‡½æ•¸
    """
    # å®šç¾©å¯ç”¨çš„æ•¸æ“šè¡¨
    available_tables = {
        '1': ('data/financialGrowth.csv', 'è²¡å‹™æˆé•·æ•¸æ“š'),
        '2': ('data/ratios.csv', 'è²¡å‹™æ¯”ç‡æ•¸æ“š'),
        '3': ('data/cashFlowStatementGrowth.csv', 'ç¾é‡‘æµé‡è¡¨æˆé•·æ•¸æ“š'),
        '4': ('data/incomeStatementGrowth.csv', 'æç›Šè¡¨æˆé•·æ•¸æ“š'),
        '5': ('data/balanceSheetStatementGrowth.csv', 'è³‡ç”¢è² å‚µè¡¨æˆé•·æ•¸æ“š'),
        # æœªä¾†å¯ä»¥åœ¨é€™è£¡æ–°å¢æ›´å¤šè¡¨æ ¼
        # '6': ('data/newTable.csv', 'æ–°çš„è²¡å‹™æ•¸æ“š'),
    }
    
    # å®šç¾©å¯ç”¨çš„æ—¥è³‡æ–™è¡¨
    daily_tables_available = {
        'd1': ('data/tech5.csv', 'Tech5æŠ€è¡“æŒ‡æ¨™æ•¸æ“š'),
        'd2': ('data/tech20.csv', 'Tech20æŠ€è¡“æŒ‡æ¨™æ•¸æ“š'),
        'd3': ('data/tech60.csv', 'Tech60æŠ€è¡“æŒ‡æ¨™æ•¸æ“š'),
        'd4': ('data/tech252.csv', 'Tech252æŠ€è¡“æŒ‡æ¨™æ•¸æ“š'),
        # æœªä¾†å¯ä»¥åœ¨é€™è£¡æ–°å¢æ›´å¤šæ—¥è³‡æ–™è¡¨æ ¼
    }
    
    print("=== è‚¡ç¥¨æ•¸æ“šåˆä½µå·¥å…· ===")
    print("\nğŸ“Š ä¸»è¡¨èªªæ˜:")
    print("â€¢ ä¸»è¡¨: data/historicalPriceFull.csv (æ¯æ—¥æ­·å²è‚¡åƒ¹æ•¸æ“š)")
    print("â€¢ åˆä½µæ–¹å¼: å„ªå…ˆåˆä½µå­£åº¦è²¡å‹™æ•¸æ“šï¼Œç„¶å¾Œåˆä½µæ—¥æŠ€è¡“æŒ‡æ¨™æ•¸æ“š")
    print("â€¢ å­£åº¦æ•¸æ“šæœƒå¡«å…¥å°æ‡‰å­£åº¦å…§çš„æ‰€æœ‰äº¤æ˜“æ—¥")
    print("â€¢ æ—¥è³‡æ–™æ•¸æ“šåŸºæ–¼æ—¥æœŸç›´æ¥åŒ¹é…åˆä½µ")
    
    print("ğŸ“‹ å¯ç”¨çš„è²¡å‹™æ•¸æ“šè¡¨ (å­£åº¦æ•¸æ“š):")
    for key, (_, name) in available_tables.items():
        print(f"{key}. {name}")
    
    print("\nï¿½ å¯ç”¨çš„æŠ€è¡“æŒ‡æ¨™è¡¨ (æ—¥è³‡æ–™):")
    for key, (_, name) in daily_tables_available.items():
        print(f"{key}. {name}")
    
    print("\nï¿½ğŸ”§ ä½¿ç”¨èªªæ˜:")
    print("â€¢ è²¡å‹™æ•¸æ“š: è«‹é¸æ“‡è¦åˆä½µçš„è²¡å‹™æ•¸æ“šè¡¨ï¼ˆå¯å¤šé¸ï¼‰")
    print("  ä¾‹å¦‚: è¼¸å…¥ '1,2' è¡¨ç¤ºåŒæ™‚åˆä½µè²¡å‹™æˆé•·æ•¸æ“šå’Œè²¡å‹™æ¯”ç‡æ•¸æ“š")
    print("â€¢ æŠ€è¡“æŒ‡æ¨™: è«‹é¸æ“‡è¦åˆä½µçš„æŠ€è¡“æŒ‡æ¨™è¡¨ï¼ˆå¯å¤šé¸ï¼‰")
    print("  ä¾‹å¦‚: è¼¸å…¥ 'd1,d2' è¡¨ç¤ºåŒæ™‚åˆä½µTech5å’ŒTech20æ•¸æ“š")
    print("â€¢ å¯ä»¥åŒæ™‚é¸æ“‡è²¡å‹™æ•¸æ“šå’ŒæŠ€è¡“æŒ‡æ¨™")
    print("  ä¾‹å¦‚: è²¡å‹™é¸æ“‡ '1,2'ï¼ŒæŠ€è¡“æŒ‡æ¨™é¸æ“‡ 'd1' è¡¨ç¤ºåˆä½µè²¡å‹™æˆé•·ã€è²¡å‹™æ¯”ç‡å’ŒTech5æ•¸æ“š")
    
    # é¸æ“‡è²¡å‹™æ•¸æ“šè¡¨
    financial_input = input("\nè«‹é¸æ“‡è²¡å‹™æ•¸æ“šè¡¨ï¼ˆç”¨é€—è™Ÿåˆ†éš”ï¼Œç•™ç©ºè¡¨ç¤ºä¸é¸æ“‡ï¼‰: ").strip()
    
    # é¸æ“‡æŠ€è¡“æŒ‡æ¨™è¡¨
    daily_input = input("è«‹é¸æ“‡æŠ€è¡“æŒ‡æ¨™è¡¨ï¼ˆç”¨é€—è™Ÿåˆ†éš”ï¼Œç•™ç©ºè¡¨ç¤ºä¸é¸æ“‡ï¼‰: ").strip()
    
    # æª¢æŸ¥æ˜¯å¦éƒ½ç‚ºç©º
    if not financial_input and not daily_input:
        print("æœªé¸æ“‡ä»»ä½•æ•¸æ“šè¡¨ï¼Œç¨‹å¼çµæŸ")
        return
    
    try:
        selected_tables = []
        selected_daily_tables = []
        
        # è§£æè²¡å‹™æ•¸æ“šé¸æ“‡
        if financial_input:
            financial_keys = [key.strip() for key in financial_input.split(',')]
            for key in financial_keys:
                if key in available_tables:
                    selected_tables.append(available_tables[key])
                else:
                    print(f"è­¦å‘Š: ç„¡æ•ˆçš„è²¡å‹™æ•¸æ“šé¸æ“‡ '{key}'ï¼Œå·²å¿½ç•¥")
        
        # è§£ææŠ€è¡“æŒ‡æ¨™é¸æ“‡
        if daily_input:
            daily_keys = [key.strip() for key in daily_input.split(',')]
            for key in daily_keys:
                if key in daily_tables_available:
                    selected_daily_tables.append(daily_tables_available[key])
                else:
                    print(f"è­¦å‘Š: ç„¡æ•ˆçš„æŠ€è¡“æŒ‡æ¨™é¸æ“‡ '{key}'ï¼Œå·²å¿½ç•¥")
        
        if not selected_tables and not selected_daily_tables:
            print("æ²’æœ‰æœ‰æ•ˆçš„é¸æ“‡ï¼Œç¨‹å¼çµæŸ")
            return
        
        # é¡¯ç¤ºå°‡è¦åˆä½µçš„è¡¨æ ¼
        if selected_tables:
            print(f"\nå°‡åˆä½µä»¥ä¸‹è²¡å‹™æ•¸æ“šè¡¨:")
            for _, name in selected_tables:
                print(f"- {name}")
        
        if selected_daily_tables:
            print(f"\nå°‡åˆä½µä»¥ä¸‹æŠ€è¡“æŒ‡æ¨™è¡¨:")
            for _, name in selected_daily_tables:
                print(f"- {name}")
        
        # ç”Ÿæˆè¼¸å‡ºæ–‡ä»¶å
        all_table_names = []
        if selected_tables:
            all_table_names.extend([name.replace('æ•¸æ“š', '') for _, name in selected_tables])
        if selected_daily_tables:
            all_table_names.extend([name.replace('æ•¸æ“š', '') for _, name in selected_daily_tables])
        
        output_file = f"merged_{'_'.join(all_table_names)}_data.csv"
        
        print(f"\né–‹å§‹åˆä½µæ•¸æ“š...")
        
        # åŸ·è¡Œåˆä½µï¼ˆåŒ…å«æ—¥è³‡æ–™å’Œå­£åº¦æ•¸æ“šï¼‰
        result_df = merge_selected_data(selected_tables, selected_daily_tables)
        
        # ä¿å­˜çµæœ
        print(f"\næ­£åœ¨ä¿å­˜åˆä½µå¾Œçš„æ•¸æ“šåˆ°: {output_file}")
        result_df.to_csv(output_file, index=False)
        
        # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
        print(f"\n=== åˆä½µå®Œæˆ! ===")
        print(f"æœ€çµ‚æ•¸æ“šç¶­åº¦: {result_df.shape}")
        print(f"è¼¸å‡ºæ–‡ä»¶: {output_file}")
        
        # é¡¯ç¤ºæ•¸æ“šè¦†è“‹ç‡çµ±è¨ˆ
        historical_cols = ['date', 'symbol', 'open', 'high', 'low', 'close', 'adjClose', 
                          'volume', 'unadjustedVolume', 'change', 'changePercent', 
                          'vwap', 'label', 'changeOverTime']
        
        # åˆ†åˆ¥çµ±è¨ˆè²¡å‹™æ•¸æ“šå’ŒæŠ€è¡“æŒ‡æ¨™çš„è¦†è“‹ç‡
        if selected_tables:
            financial_cols = []
            for _, name in selected_tables:
                # æ ¹æ“šä¸åŒçš„è²¡å‹™æ•¸æ“šè¡¨ï¼Œæ·»åŠ ç›¸æ‡‰çš„åˆ—
                if 'è²¡å‹™æˆé•·' in name:
                    financial_cols.extend([col for col in result_df.columns if any(x in col.lower() for x in ['growth', 'revenue', 'income', 'profit'])])
                elif 'æ¯”ç‡' in name:
                    financial_cols.extend([col for col in result_df.columns if any(x in col.lower() for x in ['ratio', 'margin', 'return'])])
            
            financial_cols = list(set(financial_cols))  # å»é‡
            if financial_cols:
                total_rows = len(result_df)
                rows_with_financial = len(result_df.dropna(subset=financial_cols, how='all'))
                print(f"è²¡å‹™æ•¸æ“šè¦†è“‹ç‡: {rows_with_financial/total_rows*100:.2f}% ({rows_with_financial}/{total_rows})")
        
        if selected_daily_tables:
            tech_cols = [col for col in result_df.columns if any(x in col.lower() for x in ['tech5', 'tech20', 'tech60', 'tech252', 'sma', 'ema', 'rsi'])]
            if tech_cols:
                total_rows = len(result_df)
                rows_with_tech = len(result_df.dropna(subset=tech_cols, how='all'))
                print(f"æŠ€è¡“æŒ‡æ¨™è¦†è“‹ç‡: {rows_with_tech/total_rows*100:.2f}% ({rows_with_tech}/{total_rows})")
        
    except Exception as e:
        print(f"åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == "__main__":
    main()